{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac024473-1604-4a3d-ac88-4076140633a2",
   "metadata": {},
   "source": [
    "# The Beatles: Discography Lyrics Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6836c9-a44d-4303-b236-297ae762cd30",
   "metadata": {},
   "source": [
    "## DESCRIPTION:\n",
    "This Jupyter Notebook assosiated with \"The Beatles: Discography Lyrics Analysis\" will explain how the data was processed for the purpose of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569b9f2-a442-4d2a-a845-dfc08210103b",
   "metadata": {},
   "source": [
    "### IMPORT\n",
    "First we want to import all the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f821752-73ce-4888-aff5-6a0cb3296f58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Janek/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "!spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e207a39-efbe-46a9-bf44-d15c861a070d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CONVERSION\n",
    "\n",
    "As the main corpus equals to The Beatles discography, it consist 13 folders (albums) with .txt files (tracks). Below is python code that did the conversion to the .csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62d8148b-ffb9-4db6-897a-7cde6b675614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_files(folder):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder, filename), 'r', encoding='utf-8') as file:\n",
    "                track = filename.replace('.txt', '')\n",
    "                lyrics = file.read()\n",
    "                data.append({\"id\": len(data) + 1, \"album\": os.path.basename(folder), \"track\": track, \"lyrics\": lyrics})\n",
    "    return data\n",
    "\n",
    "def convert_to_csv(input_folders, output_csv):\n",
    "    all_data = []\n",
    "    for f in input_folders:\n",
    "        folder_data = read_text_files(f)\n",
    "        all_data.extend(folder_data)\n",
    "\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = [\"id\", \"album\", \"track\", \"lyrics\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in all_data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "input_folders = [\n",
    "    \"texts/Please Please Me\",\n",
    "    \"texts/Let It Be\",\n",
    "    \"texts/Abbey Road\",\n",
    "    \"texts/Yellow Submarine\",\n",
    "    \"texts/The Beatles\",\n",
    "    \"texts/Magical Mystery Tour\",\n",
    "    \"texts/Sgt. Pepper's Lonely Hearts Club Band\",\n",
    "    \"texts/Revolver\",\n",
    "    \"texts/Rubber Soul\",\n",
    "    \"texts/Help!\",\n",
    "    \"texts/Beatles For Sale\",\n",
    "    \"texts/A Hard Day's Night\",\n",
    "    \"texts/With The Beatles\"\n",
    "]\n",
    "output_csv = \"clean_TheBeatles.csv\"\n",
    "\n",
    "convert_to_csv(input_folders, output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d23e9d-ab64-4e82-b114-2778f61aab7c",
   "metadata": {},
   "source": [
    "### SPACY ANNOTATION\n",
    "First spaCy is used to create a token called 'Doc' and process the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82ebd6e2-0659-4d6b-9176-d16e054faa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# Initialize spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "df = pd.read_csv('clean_TheBeatles.csv')\n",
    "\n",
    "# Use spaCy\n",
    "def process_text(text):\n",
    "    return nlp(text)\n",
    "\n",
    "df['Doc'] = df['lyrics'].apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d182f28-65ea-4d85-8674-ed1d3c93c3fc",
   "metadata": {},
   "source": [
    "Now, the processed text is tokenized, creating a Tokenized version of every song lyrics in the CSV and dataframe formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9977e9a-7693-4a65-9e77-4527a16b8a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last night I said these words to my girl, I kn...</td>\n",
       "      <td>[Last, night, I, said, these, words, to, my, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sha la la la la la la la Sha la la la la la la...</td>\n",
       "      <td>[Sha, la, la, la, la, la, la, la, Sha, la, la,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There, there's a place where I can go When I f...</td>\n",
       "      <td>[There, ,, there, 's, a, place, where, I, can,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well, shake it up, baby, now (shake it up, bab...</td>\n",
       "      <td>[Well, ,, shake, it, up, ,, baby, ,, now, (, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I been told when a boy kiss a girl Take a trip...</td>\n",
       "      <td>[I, been, told, when, a, boy, kiss, a, girl, T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics  \\\n",
       "0  Last night I said these words to my girl, I kn...   \n",
       "1  Sha la la la la la la la Sha la la la la la la...   \n",
       "2  There, there's a place where I can go When I f...   \n",
       "3  Well, shake it up, baby, now (shake it up, bab...   \n",
       "4  I been told when a boy kiss a girl Take a trip...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [Last, night, I, said, these, words, to, my, g...  \n",
       "1  [Sha, la, la, la, la, la, la, la, Sha, la, la,...  \n",
       "2  [There, ,, there, 's, a, place, where, I, can,...  \n",
       "3  [Well, ,, shake, it, up, ,, baby, ,, now, (, s...  \n",
       "4  [I, been, told, when, a, boy, kiss, a, girl, T...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_token(doc):\n",
    "    return [(token.text) for token in doc]\n",
    "df['tokens'] = df['Doc'].apply(get_token)\n",
    "\n",
    "tokens = df[['lyrics', 'tokens']].copy()\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77230de-84b0-4834-aa5d-12562d765ffb",
   "metadata": {},
   "source": [
    "Next parts of code use the processed text in the 'Doc' column to create columns consisting of the Lemma's, Part-of-Speech, Named Entities and the words of Named Entities of the original processed text, every row being a separate song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a20cd6f-a425-425d-882b-56b1445322f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "def get_lemma(doc):\n",
    "    return [(token.lemma_) for token in doc]\n",
    "\n",
    "df['lemmas'] = df['Doc'].apply(get_lemma)\n",
    "\n",
    "# Part-of-Speech\n",
    "def get_pos(doc):\n",
    "    return [(token.pos_, token.tag_) for token in doc]\n",
    "\n",
    "df['POS'] = df['Doc'].apply(get_pos)\n",
    "\n",
    "# Named Entities\n",
    "def extract_named_entities(doc):\n",
    "    return [ent.label_ for ent in doc.ents]\n",
    "\n",
    "df['Named_Entities'] = df['Doc'].apply(extract_named_entities)\n",
    "\n",
    "# Named Entities Words\n",
    "def extract_ne_words(doc):\n",
    "    return [ent for ent in doc.ents]\n",
    "\n",
    "df['NE_Words'] = df['Doc'].apply(extract_ne_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d78db1-0ace-49e9-b7ee-29022e150091",
   "metadata": {},
   "source": [
    "The last step shows the final result of the DataFrame, and saves it into a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8afa64f4-a797-4430-9178-675d68d9f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "df.head()\n",
    "\n",
    "# Save into a new .csv file\n",
    "df.to_csv('TheBeatles_annotation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69ee7f-92e5-4e75-9aa1-50617aa24ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
